{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uj-user/Yo/hybrid-ltm/ltm-venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/home/uj-user/Yo/hybrid-ltm/data-80/context-fms-train/MS_DG/test.jsonl\"\n",
    "data_path = \"/home/uj-user/Yo/hybrid-ltm/data_eval/context-fms/MS_DG/last_session.jsonl\"\n",
    "\n",
    "# model_name = \"/home/uj-user/Yo/hybrid-ltm/model/llama-7b_ALL\"\n",
    "model_name = \"/home/uj-user/Yo/hybrid-ltm/model/llama-7b_MS_DG\"\n",
    "# model_name = \"gpt2\"\n",
    "max_len = 2048\n",
    "target_len = 128\n",
    "device = \"cuda:2\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.31it/s]\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.bfloat16).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>```You will be shown a 1 session dialogues bet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>```You will be shown a 1 session dialogues bet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>```You will be shown a 1 session dialogues bet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>```You will be shown a 1 session dialogues bet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>```You will be shown a 1 session dialogues bet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>```You will be shown a 1 session dialogues bet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>```You will be shown a 1 session dialogues bet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>```You will be shown a 1 session dialogues bet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>```You will be shown a 1 session dialogues bet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>```You will be shown a 1 session dialogues bet...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                input\n",
       "0   ```You will be shown a 1 session dialogues bet...\n",
       "1   ```You will be shown a 1 session dialogues bet...\n",
       "2   ```You will be shown a 1 session dialogues bet...\n",
       "3   ```You will be shown a 1 session dialogues bet...\n",
       "4   ```You will be shown a 1 session dialogues bet...\n",
       "..                                                ...\n",
       "75  ```You will be shown a 1 session dialogues bet...\n",
       "76  ```You will be shown a 1 session dialogues bet...\n",
       "77  ```You will be shown a 1 session dialogues bet...\n",
       "78  ```You will be shown a 1 session dialogues bet...\n",
       "79  ```You will be shown a 1 session dialogues bet...\n",
       "\n",
       "[80 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_json(data_path, lines=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaTokenizer(name_or_path='/home/uj-user/Yo/hybrid-ltm/model/llama-7b_MS_DG', vocab_size=32000, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side='right', truncation_side='left', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '</s>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name, truncation_side='left', use_fast=False)\n",
    "# tokenizer.add_special_tokens({'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '</s>'})\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"```You will be shown a 1 session dialogues between Patient and Doctor. Please read and understand given multiple Dialogue Session, then complete the task under the guidance of Task Introduction.\\n\\n\\nDialogue Session #3:\\nDoctor:Hello Patient, how can I assist you today?\\nPatient:Hi Doctor, I've been thinking of traveling to a new destination.\\nDoctor:That sounds like a great idea. Have you decided on where you want to go?\\nPatient:I haven't decided yet, but I'm looking for recommendations.\\nDoctor:Well, I recently went to Japan and it was a wonderful experience. The culture, food, and people were amazing.\\nPatient:That sounds interesting. How was the travel experience for you?\\nDoctor:It was a long flight, but I made sure to stay hydrated and take breaks to stretch. Have you traveled internationally before?\\nPatient:Yes, a few years ago I went to Europe.\\nDoctor:That's great. Did you have any issues with your health during that trip?\\nPatient:No, everything was fine. Although, I did experience some jet lag when I arrived back home.\\nDoctor: ###\\n```\\n\\n```\\nTask Introduction:\\nAfter reading the entire Dialogue Sessions, please create an appropriate response.\\n```\\n\\nTask Result:```\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['input'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n"
     ]
    }
   ],
   "source": [
    "ans_jsons = []\n",
    "for i, line in enumerate(tqdm(dataset['input'])):\n",
    "    input = tokenizer([dataset['input'][i]], max_length=(max_len-target_len), truncation=True, return_tensors='pt').to(device)#.input_ids\n",
    "    target_len = min(len(input.input_ids[0])+target_len, max_len)\n",
    "    output_ids = model.generate(\n",
    "        **input,\n",
    "        do_sample=True,\n",
    "        max_length=target_len,\n",
    "        encoder_no_repeat_ngram_size=None\n",
    "    )\n",
    "    output_ids = output_ids[0][len(input.input_ids[0]):]\n",
    "    outputs = tokenizer.decode(output_ids, skip_special_tokens=True).strip()\n",
    "    # print('input:\\n', tokenizer.decode(input.input_ids[0]))\n",
    "    # print('output:\\n', outputs)\n",
    "    # if i%3==1:\n",
    "    #     break\n",
    "    # print(i)\n",
    "    ans_jsons.append(\n",
    "        {\n",
    "            \"question_id\": i,\n",
    "            \"text\": outputs,\n",
    "            \"model_id\": model_name,\n",
    "            \"metadata\": {},\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = f\"predictions/{model_name}_{data_path.split('/')[-2]}.json\"\n",
    "save_path = os.path.dirname(filename)\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "df_ans_json = pd.DataFrame(ans_jsons)\n",
    "df_ans_json.to_json(filename, orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = f\"predictions/{model_name}_{data_path.split('/')[-2]}_last.json\"\n",
    "save_path = os.path.dirname(filename)\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "df_ans_json = pd.DataFrame(ans_jsons)\n",
    "df_ans_json.to_json(filename, orient='records', lines=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ltm-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
