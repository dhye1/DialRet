{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uj-user/Yo/hybrid-ltm/ltm-venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/home/uj-user/Yo/hybrid-ltm/data_eval/context-fms/MS_DG/test.jsonl\"\n",
    "model_name = \"facebook/blenderbot-3B\"\n",
    "# model_name = \"gpt2\"\n",
    "target_len = 128\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>eval_indicator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>```\\nDialogue Session #1:\\nPatient: Hi, doctor...</td>\n",
       "      <td>Doctor:Ah yes, jet lag can be tough. It's impo...</td>\n",
       "      <td>Engagingness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>```\\nDialogue Session #1:\\nNeighbors A:Hi, Nei...</td>\n",
       "      <td>Neighbors A:Well, I have some experience with ...</td>\n",
       "      <td>Specificity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>```\\nDialogue Session #1:\\nCo-workers A:I have...</td>\n",
       "      <td>Co-workers B:That's a good perspective to have...</td>\n",
       "      <td>Memorability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>```\\nDialogue Session #1:\\nMentee:Mentor, I we...</td>\n",
       "      <td>Mentee:Exactly, Mentor. I remember a time in m...</td>\n",
       "      <td>Specificity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>```\\nDialogue Session #1:\\nClassmates A:Hey, g...</td>\n",
       "      <td>Classmates B:Yes, I'll never forget that. It w...</td>\n",
       "      <td>Humanness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>```\\nDialogue Session #1:\\nHusband:You always ...</td>\n",
       "      <td>Wife:Sure, we can do that. You know, speaking ...</td>\n",
       "      <td>Engagingness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>```\\nDialogue Session #1:\\nClassmates A:Hey, B...</td>\n",
       "      <td>Classmates A:Thanks, I just did what I had to ...</td>\n",
       "      <td>Memorability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>```\\nDialogue Session #1:\\nClassmates A:Hey, B...</td>\n",
       "      <td>Classmates A:I like the idea of serving my cou...</td>\n",
       "      <td>Specificity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>```\\nDialogue Session #1:\\nHusband:I really do...</td>\n",
       "      <td>Husband:It might be worth getting a second opi...</td>\n",
       "      <td>Specificity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>```\\nDialogue Session #1:\\nPatient: Doctor, I ...</td>\n",
       "      <td>Patient:Honestly, much better. I went back to ...</td>\n",
       "      <td>Memorability</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                input  \\\n",
       "0   ```\\nDialogue Session #1:\\nPatient: Hi, doctor...   \n",
       "1   ```\\nDialogue Session #1:\\nNeighbors A:Hi, Nei...   \n",
       "2   ```\\nDialogue Session #1:\\nCo-workers A:I have...   \n",
       "3   ```\\nDialogue Session #1:\\nMentee:Mentor, I we...   \n",
       "4   ```\\nDialogue Session #1:\\nClassmates A:Hey, g...   \n",
       "..                                                ...   \n",
       "75  ```\\nDialogue Session #1:\\nHusband:You always ...   \n",
       "76  ```\\nDialogue Session #1:\\nClassmates A:Hey, B...   \n",
       "77  ```\\nDialogue Session #1:\\nClassmates A:Hey, B...   \n",
       "78  ```\\nDialogue Session #1:\\nHusband:I really do...   \n",
       "79  ```\\nDialogue Session #1:\\nPatient: Doctor, I ...   \n",
       "\n",
       "                                               output eval_indicator  \n",
       "0   Doctor:Ah yes, jet lag can be tough. It's impo...   Engagingness  \n",
       "1   Neighbors A:Well, I have some experience with ...    Specificity  \n",
       "2   Co-workers B:That's a good perspective to have...   Memorability  \n",
       "3   Mentee:Exactly, Mentor. I remember a time in m...    Specificity  \n",
       "4   Classmates B:Yes, I'll never forget that. It w...      Humanness  \n",
       "..                                                ...            ...  \n",
       "75  Wife:Sure, we can do that. You know, speaking ...   Engagingness  \n",
       "76  Classmates A:Thanks, I just did what I had to ...   Memorability  \n",
       "77  Classmates A:I like the idea of serving my cou...    Specificity  \n",
       "78  Husband:It might be worth getting a second opi...    Specificity  \n",
       "79  Patient:Honestly, much better. I went back to ...   Memorability  \n",
       "\n",
       "[80 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_json(data_path, lines=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BlenderbotTokenizer(name_or_path='facebook/blenderbot-3B', vocab_size=8008, model_max_length=128, is_fast=False, padding_side='right', truncation_side='left', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': '<mask>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "\t3: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t8008: AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name, truncation_side='left', use_fast=False)\n",
    "# tokenizer.add_special_tokens({'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '</s>'})\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_jsons = []\n",
    "for i, line in enumerate(dataset['input']):\n",
    "    input = tokenizer([dataset['input'][i][:-8]], max_length=64, truncation=True, return_tensors='pt').to(device)#.input_ids\n",
    "    output_ids = model.generate(\n",
    "        **input,\n",
    "        do_sample=True,\n",
    "        max_length=target_len,\n",
    "        encoder_no_repeat_ngram_size=None\n",
    "    )\n",
    "    output_ids = output_ids[0][len(input.input_ids[0]):]\n",
    "    outputs = tokenizer.decode(output_ids, skip_special_tokens=True).strip()\n",
    "    # print('input:\\n', tokenizer.decode(input.input_ids[0]))\n",
    "    # print('output:\\n', outputs)\n",
    "    # if i%3==1:\n",
    "    #     break\n",
    "    \n",
    "    ans_jsons.append(\n",
    "        {\n",
    "            \"question_id\": i,\n",
    "            \"text\": outputs,\n",
    "            \"model_id\": model_name,\n",
    "            \"metadata\": {},\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = f\"{model_name}_{data_path.split('/')[-2]}.json\"\n",
    "save_path = os.path.dirname(filename)\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "df_ans_json = pd.DataFrame(ans_jsons)\n",
    "df_ans_json.to_json(filename, orient='records', lines=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ltm-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
