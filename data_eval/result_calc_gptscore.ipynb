{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "from glob import glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_gpt_score(df:pd.DataFrame, model_name:str, cross_domain:str)->pd.DataFrame:\n",
    "    \n",
    "    Humanness = df[df['eval_indicator']=='Humanness']['rating'].mean()\n",
    "    Engagingness = df[df['eval_indicator']=='Engagingness']['rating'].mean()\n",
    "    Memorability = df[df['eval_indicator']=='Memorability']['rating'].mean()\n",
    "    Specificity = df[df['eval_indicator']=='Specificity']['rating'].mean()\n",
    "    \n",
    "    Humanness_len = len(df[df['eval_indicator']=='Humanness']['rating'])\n",
    "    Engagingness_len = len(df[df['eval_indicator']=='Engagingness']['rating'])\n",
    "    Memorability_len = len(df[df['eval_indicator']=='Memorability']['rating'])\n",
    "    Specificity_len = len(df[df['eval_indicator']=='Specificity']['rating'])\n",
    "    \n",
    "    Avg = df['rating'].mean()\n",
    "    \n",
    "    gptscore = {'model':model_name, 'cross_domain':cross_domain, \n",
    "                            'Humanness':round(Humanness,2),'Engagingness':round(Engagingness,2),\n",
    "                            'Memorability':round(Memorability,2),'Specificity':round(Specificity,2),\n",
    "                            'Avg':round(Avg,2),\n",
    "                            'H_len':Humanness_len, 'E_len':Engagingness_len, 'M_len':Memorability_len,'S_len':Specificity_len,\n",
    "                           }\n",
    "    return gptscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blenderbot-3B_zeroshot\n",
      "rebot-generation_zeroshot\n",
      "GODEL-v1_1-large-seq2seq_zeroshot\n",
      "DialoGPT-large_zeroshot\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>cross_domain</th>\n",
       "      <th>Humanness</th>\n",
       "      <th>Engagingness</th>\n",
       "      <th>Memorability</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Avg</th>\n",
       "      <th>H_len</th>\n",
       "      <th>E_len</th>\n",
       "      <th>M_len</th>\n",
       "      <th>S_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DialoGPT-large_zeroshot</td>\n",
       "      <td>MS_DG</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.45</td>\n",
       "      <td>1.15</td>\n",
       "      <td>1.40</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GODEL-v1_1-large-seq2seq_zeroshot</td>\n",
       "      <td>MS_DG</td>\n",
       "      <td>2.75</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.30</td>\n",
       "      <td>1.40</td>\n",
       "      <td>2.49</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blenderbot-3B_zeroshot</td>\n",
       "      <td>MS_DG</td>\n",
       "      <td>3.65</td>\n",
       "      <td>3.1</td>\n",
       "      <td>2.45</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.00</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rebot-generation_zeroshot</td>\n",
       "      <td>MS_DG</td>\n",
       "      <td>4.65</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.00</td>\n",
       "      <td>3.90</td>\n",
       "      <td>5.39</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               model cross_domain  Humanness  Engagingness  \\\n",
       "0            DialoGPT-large_zeroshot        MS_DG       1.50           1.5   \n",
       "1  GODEL-v1_1-large-seq2seq_zeroshot        MS_DG       2.75           3.5   \n",
       "2             blenderbot-3B_zeroshot        MS_DG       3.65           3.1   \n",
       "3          rebot-generation_zeroshot        MS_DG       4.65           7.0   \n",
       "\n",
       "   Memorability  Specificity   Avg  H_len  E_len  M_len  S_len  \n",
       "0          1.45         1.15  1.40     20     20     20     20  \n",
       "1          2.30         1.40  2.49     20     20     20     20  \n",
       "2          2.45         2.80  3.00     20     20     20     20  \n",
       "3          6.00         3.90  5.39     20     20     20     20  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# folder_name = '80_reason/eval_result_api_v2_only_taskInT_reason'\n",
    "folder_name   = '80_reason/eval_result_api-v6-custom-models_reason'\n",
    "# folder_name   = '80_reason/eval_result_api_v7_other_models_reason'\n",
    "\n",
    "folder_path = glob(f'./{folder_name}/*')\n",
    "folder_paths = [glob(dir + '/*') for dir in folder_path]\n",
    "result_list = sum(folder_paths, [])\n",
    "# print(result_list)\n",
    "\n",
    "gptscore_result = []\n",
    "for result in result_list:\n",
    "    # print(result)\n",
    "    value = result.replace('.csv', '').split('+') \n",
    "    model_name = '_'.join(value[:-1]).split('/')[-1]\n",
    "    print(model_name)\n",
    "    cross_domain = value[-1]\n",
    "    df = pd.read_csv(result)\n",
    "    gptscore_result.append(calc_gpt_score(df, model_name, cross_domain))\n",
    "    \n",
    "score_df = pd.DataFrame(gptscore_result)\n",
    "score_df = score_df.sort_values(by=['cross_domain', 'model' ], ignore_index=True)\n",
    "score_df.to_csv(f'{folder_name}_gpts.csv')\n",
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mistral-7B-v0.1_zeroshot\n",
      "vicuna-13b-v1.5-16k_zeroshot\n",
      "vicuna-13b-v1.5-16k_zeroshot\n",
      "llama-13b-hf_zeroshot\n",
      "Llama-2-13b-chat-hf_zeroshot\n",
      "Llama-2-13b-chat-hf_zeroshot\n",
      "flan-t5-xxl_zeroshot\n",
      "flan-t5-xxl_zeroshot\n",
      "openchat_3.5_zeroshot\n",
      "openchat_3.5_zeroshot\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>cross_domain</th>\n",
       "      <th>Humanness</th>\n",
       "      <th>Engagingness</th>\n",
       "      <th>Memorability</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Avg</th>\n",
       "      <th>H_len</th>\n",
       "      <th>E_len</th>\n",
       "      <th>M_len</th>\n",
       "      <th>S_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Llama-2-13b-chat-hf_zeroshot</td>\n",
       "      <td>MS_DG</td>\n",
       "      <td>1.35</td>\n",
       "      <td>2.10</td>\n",
       "      <td>3.55</td>\n",
       "      <td>2.75</td>\n",
       "      <td>2.44</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mistral-7B-v0.1_zeroshot</td>\n",
       "      <td>MS_DG</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.15</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.30</td>\n",
       "      <td>2.30</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>flan-t5-xxl_zeroshot</td>\n",
       "      <td>MS_DG</td>\n",
       "      <td>3.80</td>\n",
       "      <td>2.05</td>\n",
       "      <td>2.85</td>\n",
       "      <td>1.70</td>\n",
       "      <td>2.60</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>llama-13b-hf_zeroshot</td>\n",
       "      <td>MS_DG</td>\n",
       "      <td>1.60</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.55</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1.50</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>openchat_3.5_zeroshot</td>\n",
       "      <td>MS_DG</td>\n",
       "      <td>3.30</td>\n",
       "      <td>3.70</td>\n",
       "      <td>2.95</td>\n",
       "      <td>3.05</td>\n",
       "      <td>3.25</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>vicuna-13b-v1.5-16k_zeroshot</td>\n",
       "      <td>MS_DG</td>\n",
       "      <td>3.45</td>\n",
       "      <td>2.20</td>\n",
       "      <td>2.45</td>\n",
       "      <td>3.10</td>\n",
       "      <td>2.80</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Llama-2-13b-chat-hf_zeroshot</td>\n",
       "      <td>MT_DG</td>\n",
       "      <td>2.72</td>\n",
       "      <td>3.59</td>\n",
       "      <td>3.12</td>\n",
       "      <td>3.28</td>\n",
       "      <td>3.17</td>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>flan-t5-xxl_zeroshot</td>\n",
       "      <td>MT_DG</td>\n",
       "      <td>2.90</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.10</td>\n",
       "      <td>1.35</td>\n",
       "      <td>2.62</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>openchat_3.5_zeroshot</td>\n",
       "      <td>MT_DG</td>\n",
       "      <td>5.55</td>\n",
       "      <td>5.05</td>\n",
       "      <td>4.60</td>\n",
       "      <td>6.50</td>\n",
       "      <td>5.42</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>vicuna-13b-v1.5-16k_zeroshot</td>\n",
       "      <td>MT_DG</td>\n",
       "      <td>6.05</td>\n",
       "      <td>4.80</td>\n",
       "      <td>5.50</td>\n",
       "      <td>7.55</td>\n",
       "      <td>5.98</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          model cross_domain  Humanness  Engagingness  \\\n",
       "0  Llama-2-13b-chat-hf_zeroshot        MS_DG       1.35          2.10   \n",
       "1      Mistral-7B-v0.1_zeroshot        MS_DG       1.00          1.15   \n",
       "2          flan-t5-xxl_zeroshot        MS_DG       3.80          2.05   \n",
       "3         llama-13b-hf_zeroshot        MS_DG       1.60          1.75   \n",
       "4         openchat_3.5_zeroshot        MS_DG       3.30          3.70   \n",
       "5  vicuna-13b-v1.5-16k_zeroshot        MS_DG       3.45          2.20   \n",
       "6  Llama-2-13b-chat-hf_zeroshot        MT_DG       2.72          3.59   \n",
       "7          flan-t5-xxl_zeroshot        MT_DG       2.90          3.15   \n",
       "8         openchat_3.5_zeroshot        MT_DG       5.55          5.05   \n",
       "9  vicuna-13b-v1.5-16k_zeroshot        MT_DG       6.05          4.80   \n",
       "\n",
       "   Memorability  Specificity   Avg  H_len  E_len  M_len  S_len  \n",
       "0          3.55         2.75  2.44     20     20     20     20  \n",
       "1          3.75         3.30  2.30     20     20     20     20  \n",
       "2          2.85         1.70  2.60     20     20     20     20  \n",
       "3          1.55         1.10  1.50     20     20     20     20  \n",
       "4          2.95         3.05  3.25     20     20     20     20  \n",
       "5          2.45         3.10  2.80     20     20     20     20  \n",
       "6          3.12         3.28  3.17     18     17     17     18  \n",
       "7          3.10         1.35  2.62     20     20     20     20  \n",
       "8          4.60         6.50  5.42     20     20     20     20  \n",
       "9          5.50         7.55  5.98     20     20     20     20  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_name = '80_reason/eval_result_api_v2_only_taskInT_reason'\n",
    "# folder_name   = '80_reason/eval_result_api-v6-custom-models_reason'\n",
    "# folder_name   = '80_reason/eval_result_api_v7_other_models_reason'\n",
    "\n",
    "folder_path = glob(f'./{folder_name}/*')\n",
    "folder_paths = [glob(dir + '/*') for dir in folder_path]\n",
    "result_list = sum(folder_paths, [])\n",
    "# print(result_list)\n",
    "\n",
    "gptscore_result = []\n",
    "for result in result_list:\n",
    "    # print(result)\n",
    "    value = result.replace('.csv', '').split('+') \n",
    "    model_name = '_'.join(value[:-1]).split('/')[-1]\n",
    "    print(model_name)\n",
    "    cross_domain = value[-1]\n",
    "    df = pd.read_csv(result)\n",
    "    gptscore_result.append(calc_gpt_score(df, model_name, cross_domain))\n",
    "    \n",
    "score_df = pd.DataFrame(gptscore_result)\n",
    "score_df = score_df.sort_values(by=['cross_domain', 'model' ], ignore_index=True)\n",
    "score_df.to_csv(f'{folder_name}_gpts.csv')\n",
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./80_reason/eval_result_api_v4_openAI_reason/gpt-4-1106-preview_zeroshot+MS_DG.csv', './80_reason/eval_result_api_v4_openAI_reason/gpt_3.5_turbo-1106_zeroshot+MS_DG.csv']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>cross_domain</th>\n",
       "      <th>Humanness</th>\n",
       "      <th>Engagingness</th>\n",
       "      <th>Memorability</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Avg</th>\n",
       "      <th>H_len</th>\n",
       "      <th>E_len</th>\n",
       "      <th>M_len</th>\n",
       "      <th>S_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt-4-1106-preview_zeroshot</td>\n",
       "      <td>MS_DG</td>\n",
       "      <td>8.20</td>\n",
       "      <td>8.2</td>\n",
       "      <td>7.65</td>\n",
       "      <td>7.8</td>\n",
       "      <td>7.96</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt_3.5_turbo-1106_zeroshot</td>\n",
       "      <td>MS_DG</td>\n",
       "      <td>7.95</td>\n",
       "      <td>6.3</td>\n",
       "      <td>6.45</td>\n",
       "      <td>6.3</td>\n",
       "      <td>6.75</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         model cross_domain  Humanness  Engagingness  \\\n",
       "0  gpt-4-1106-preview_zeroshot        MS_DG       8.20           8.2   \n",
       "1  gpt_3.5_turbo-1106_zeroshot        MS_DG       7.95           6.3   \n",
       "\n",
       "   Memorability  Specificity   Avg  H_len  E_len  M_len  S_len  \n",
       "0          7.65          7.8  7.96     20     20     20     20  \n",
       "1          6.45          6.3  6.75     20     20     20     20  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_name = '80_reason/eval_result_api_reason_v3_all-run'\n",
    "folder_name = '80_reason/eval_result_api_reason_v3_all_2e'\n",
    "folder_name ='80_reason/eval_result_api_v4_openAI_reason'\n",
    "\n",
    "folder_path = glob(f'./{folder_name}/*')\n",
    "result_list = folder_path\n",
    "print(result_list)\n",
    "\n",
    "gptscore_result = []\n",
    "for result in result_list:\n",
    "    value = result.replace('.csv', '').split('+')\n",
    "    model_name = '_'.join(value[:-1]).split('/')[-1]\n",
    "    cross_domain = value[-1]\n",
    "    \n",
    "    df = pd.read_csv(result)\n",
    "    gptscore_result.append(calc_gpt_score(df, model_name, cross_domain))\n",
    "\n",
    "score_df = pd.DataFrame(gptscore_result)\n",
    "score_df = score_df.sort_values(by=['cross_domain', ], ignore_index=True)\n",
    "score_df.to_csv(f'{folder_name}_gpts.csv')\n",
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6.9, 6.55, 7.35, 6.0, 6.05, 5.0, 6.15, 5.1]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_df['GPTScore'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.45, 6.79, 6.9 ],\n",
       "       [6.55, 6.15, 6.55],\n",
       "       [6.55, 7.15, 7.35],\n",
       "       [6.45, 6.55, 6.  ],\n",
       "       [5.89, 6.37, 6.05],\n",
       "       [5.35, 5.35, 5.  ],\n",
       "       [6.37, 6.3 , 6.15],\n",
       "       [5.  , 5.26, 5.1 ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data = [[6.43, 6.0, 6.89, 5.33, 7.0, 6.08, 6.73, 5.58],\n",
    "#         [6.55, 6.33, 7.38, 5.09, 6.67, 6.08, 6.8, 6.06],\n",
    "#         [8.38, 5.86, 7.5, 6.44, 6.92, 6.07, 7.0, 6.14]\n",
    "# ]\n",
    "data = [[6.45, 6.55, 6.55, 6.45, 5.89, 5.35, 6.37, 5.0],\n",
    "        [6.79, 6.15, 7.15, 6.55, 6.37, 5.35, 6.3, 5.26],\n",
    "        [6.9, 6.55, 7.35, 6.0, 6.05, 5.0, 6.15, 5.1]\n",
    "]\n",
    "data = np.array(data).transpose()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-value: 0.193563616824515\n",
      "그룹 간에는 통계적으로 유의미한 차이가 없습니다.\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats\n",
    "\n",
    "def anova_test(*groups):\n",
    "    f_statistic, p_value = scipy.stats.f_oneway(*groups)\n",
    "    \n",
    "    return p_value\n",
    "\n",
    "# 예시 데이터 (세 개의 그룹)\n",
    "group1 = [25, 30, 35, 40, 45]\n",
    "group2 = [20, 28, 32, 38, 42]\n",
    "group3 = [15, 25, 30, 35, 40]\n",
    "\n",
    "# ANOVA 검정\n",
    "# result_pvalue = anova_test(group1, group2, group3)\n",
    "result_pvalue = anova_test(data[0], data[1])\n",
    "\n",
    "print(\"P-value:\", result_pvalue)\n",
    "\n",
    "# p-value가 0.05 이하인 경우, 적어도 하나의 그룹 간에는 통계적으로 유의미한 차이가 있다고 간주할 수 있습니다.\n",
    "if result_pvalue < 0.05:\n",
    "    print(\"적어도 하나의 그룹 간에는 통계적으로 유의미한 차이가 있습니다.\")\n",
    "else:\n",
    "    print(\"그룹 간에는 통계적으로 유의미한 차이가 없습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cross</th>\n",
       "      <th>Model</th>\n",
       "      <th>ROUGE</th>\n",
       "      <th>BertScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MS_DG</td>\n",
       "      <td>llama-7b_MT_DG</td>\n",
       "      <td>0.2988</td>\n",
       "      <td>0.6806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MS_DG</td>\n",
       "      <td>llama-7b_MT2</td>\n",
       "      <td>0.3140</td>\n",
       "      <td>0.6886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MS_DG</td>\n",
       "      <td>llama-7b_MS_DG</td>\n",
       "      <td>0.3133</td>\n",
       "      <td>0.6929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MS_DG</td>\n",
       "      <td>llama-7b_MS2</td>\n",
       "      <td>0.3143</td>\n",
       "      <td>0.6837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MT_DG</td>\n",
       "      <td>llama-7b_MT_DG</td>\n",
       "      <td>0.3205</td>\n",
       "      <td>0.6946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MT_DG</td>\n",
       "      <td>llama-7b_MT2</td>\n",
       "      <td>0.3577</td>\n",
       "      <td>0.7073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MT_DG</td>\n",
       "      <td>llama-7b_MS_DG</td>\n",
       "      <td>0.3105</td>\n",
       "      <td>0.6887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MT_DG</td>\n",
       "      <td>llama-7b_MS2</td>\n",
       "      <td>0.3150</td>\n",
       "      <td>0.6785</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cross           Model   ROUGE  BertScore\n",
       "0  MS_DG  llama-7b_MT_DG  0.2988     0.6806\n",
       "1  MS_DG    llama-7b_MT2  0.3140     0.6886\n",
       "2  MS_DG  llama-7b_MS_DG  0.3133     0.6929\n",
       "3  MS_DG    llama-7b_MS2  0.3143     0.6837\n",
       "4  MT_DG  llama-7b_MT_DG  0.3205     0.6946\n",
       "5  MT_DG    llama-7b_MT2  0.3577     0.7073\n",
       "6  MT_DG  llama-7b_MS_DG  0.3105     0.6887\n",
       "7  MT_DG    llama-7b_MS2  0.3150     0.6785"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv('/home/uj-user/Yo/hybrid-ltm/data/eval_result/llama-7b+BS.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROUGE</th>\n",
       "      <th>BertScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.3205</td>\n",
       "      <td>0.6946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.3577</td>\n",
       "      <td>0.7073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3105</td>\n",
       "      <td>0.6887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.3150</td>\n",
       "      <td>0.6785</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ROUGE  BertScore\n",
       "0  0.3205     0.6946\n",
       "1  0.3577     0.7073\n",
       "2  0.3105     0.6887\n",
       "3  0.3150     0.6785"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv('/home/uj-user/Yo/hybrid-ltm/data/eval_result/llama-7b+MT_DG_BS_bak.csv')\n",
    "df2 = pd.read_csv('/home/uj-user/Yo/hybrid-ltm/data/eval_result/llama-7b+MT_DG_BS.csv')\n",
    "df1 = df1.drop(columns=['Model'])\n",
    "df2 = df2.drop(columns=['Model'])\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test for column ROUGE:\n",
      "T-statistic: -0.6751512587223705\n",
      "P-value: 0.5186131635861952\n",
      "Fail to reject the null hypothesis for column ROUGE: There is no significant difference.\n",
      "\n",
      "\n",
      "Test for column BertScore:\n",
      "T-statistic: -0.7241738477785662\n",
      "P-value: 0.4895922212199193\n",
      "Fail to reject the null hypothesis for column BertScore: There is no significant difference.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# 예제 데이터프레임 생성\n",
    "# data1 = {'A': [6.43, 6.0, 6.89, 5.33, 7.0, 6.08, 6.73, 5.58]}\n",
    "# data1 = {'A': [6.54, 6.32, 7.35, 5.08, 6.68, 6.08, 6.8, 6.06]}\n",
    "\n",
    "# data2 = {'A': [6.55, 6.33, 7.38, 5.09, 6.67, 6.08, 6.8, 6.06]}\n",
    "\n",
    "# df1 = pd.DataFrame(data1)\n",
    "# df2 = pd.DataFrame(data2)\n",
    "\n",
    "# 열마다 t-검정 수행\n",
    "for column in df1.columns:\n",
    "    t_statistic, p_value = ttest_ind(df1[column], df2[column])\n",
    "    print(f'Test for column {column}:')\n",
    "    print(f'T-statistic: {t_statistic}')\n",
    "    print(f'P-value: {p_value}')\n",
    "\n",
    "    # P-value가 유의수준(예: 0.05)보다 작으면 귀무가설 기각\n",
    "    if p_value < 0.05:\n",
    "        print(f'Reject the null hypothesis for column {column}: There is a significant difference.')\n",
    "    else:\n",
    "        print(f'Fail to reject the null hypothesis for column {column}: There is no significant difference.')\n",
    "\n",
    "    print('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ltm-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
